{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caca4edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_env_report.py\n",
    "# Prints OS, Python, TensorFlow, GPU, CUDA/cuDNN (where available) in one go.\n",
    "\n",
    "import os\n",
    "import platform\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def run(cmd):\n",
    "    try:\n",
    "        out = subprocess.check_output(cmd, stderr=subprocess.STDOUT, text=True)\n",
    "        return out.strip()\n",
    "    except Exception as e:\n",
    "        return f\"[not available] ({e})\"\n",
    "\n",
    "print(\"\\n=== SYSTEM ===\")\n",
    "print(\"OS:\", platform.platform())\n",
    "print(\"Machine:\", platform.machine())\n",
    "print(\"Processor:\", platform.processor())\n",
    "print(\"Python:\", sys.version.replace(\"\\n\", \" \"))\n",
    "\n",
    "print(\"\\n=== NVIDIA / CUDA (via nvidia-smi) ===\")\n",
    "print(run([\"nvidia-smi\"]))\n",
    "\n",
    "print(\"\\n=== TENSORFLOW ===\")\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    print(\"TensorFlow version:\", tf.__version__)\n",
    "    print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "    print(\"GPUs detected:\", tf.config.list_physical_devices(\"GPU\"))\n",
    "\n",
    "    # Build info (often includes CUDA and cuDNN versions for TF builds)\n",
    "    try:\n",
    "        bi = tf.sysconfig.get_build_info()\n",
    "        print(\"\\nTensorFlow build info:\")\n",
    "        for k in sorted(bi.keys()):\n",
    "            print(f\"  {k}: {bi[k]}\")\n",
    "    except Exception as e:\n",
    "        print(\"tf.sysconfig.get_build_info() not available:\", e)\n",
    "\n",
    "    # CUDA / cuDNN runtime versions (may be available depending on TF version)\n",
    "    try:\n",
    "        from tensorflow.python.platform import build_info as tf_build_info\n",
    "        print(\"\\nTensorFlow internal build_info (if available):\")\n",
    "        for k in dir(tf_build_info):\n",
    "            if \"cuda\" in k.lower() or \"cudnn\" in k.lower() or \"tensorrt\" in k.lower():\n",
    "                print(f\"  {k}: {getattr(tf_build_info, k)}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"TensorFlow not importable:\", e)\n",
    "\n",
    "print(\"\\n=== CUDA TOOLKIT (if installed) ===\")\n",
    "print(\"nvcc --version:\")\n",
    "print(run([\"nvcc\", \"--version\"]))\n",
    "\n",
    "print(\"\\n=== cuDNN (common Linux paths; may not exist on Windows) ===\")\n",
    "# This is best-effort; on Windows, cuDNN is usually inside CUDA folders or TF wheels.\n",
    "cudnn_paths = [\n",
    "    \"/usr/include/cudnn_version.h\",\n",
    "    \"/usr/local/cuda/include/cudnn_version.h\",\n",
    "]\n",
    "found = False\n",
    "for p in cudnn_paths:\n",
    "    if os.path.exists(p):\n",
    "        found = True\n",
    "        print(f\"Found: {p}\")\n",
    "        print(run([\"bash\", \"-lc\", f\"grep -E 'CUDNN_(MAJOR|MINOR|PATCHLEVEL)' {p}\"]))\n",
    "if not found:\n",
    "    print(\"[not found in common paths]\")\n",
    "\n",
    "print(\"\\n=== END ===\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
