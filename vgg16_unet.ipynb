{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2a2890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, Concatenate, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to split an image into tiles\n",
    "def split_image_into_tiles(image_path, mask_path, tile_size):\n",
    "    img = tifffile.imread(image_path)\n",
    "    mask = tifffile.imread(mask_path)\n",
    "\n",
    "    mask = mask[:, :, 0] if len(mask.shape) == 3 else mask\n",
    "    print(f\"Original Image Dimensions: {img.shape}\")\n",
    "    tiles_img = []\n",
    "    tiles_mask = []\n",
    "\n",
    "    for x in range(0, img.shape[1], tile_size):\n",
    "        for y in range(0, img.shape[0], tile_size):\n",
    "            tile_img = img[y:y+tile_size, x:x+tile_size, :] if len(img.shape) == 3 else img[y:y+tile_size, x:x+tile_size]\n",
    "            tile_mask = mask[y:y+tile_size, x:x+tile_size]\n",
    "\n",
    "            # Resize to the desired size\n",
    "            tile_img = cv2.resize(tile_img, (size, size))\n",
    "            tile_mask = cv2.resize(tile_mask, (size, size))\n",
    "            tile_mask = (tile_mask > 0).astype(np.uint8)\n",
    "\n",
    "            tiles_img.append(tile_img)\n",
    "            tiles_mask.append(tile_mask)\n",
    "\n",
    "    # Calculate the number of tiles needed to form a perfect square\n",
    "    num_tiles = len(tiles_img)\n",
    "    perfect_square_size = int(np.ceil(np.sqrt(num_tiles)))\n",
    "    total_tiles_needed = perfect_square_size**2\n",
    "    num_tiles_to_add = total_tiles_needed - num_tiles\n",
    "\n",
    "    # Pad the list of tiles with zeros\n",
    "    for _ in range(num_tiles_to_add):\n",
    "        tiles_img.append(np.zeros((size, size, img.shape[2]), dtype=np.uint8))\n",
    "        tiles_mask.append(np.zeros((size, size), dtype=np.uint8))\n",
    "\n",
    "    tiles_img = np.array(tiles_img)\n",
    "    tiles_mask = np.array(tiles_mask)\n",
    "\n",
    "    return tiles_img, tiles_mask\n",
    "\n",
    "# Function to load data\n",
    "def load_data(image_dir, mask_dir, tile_size):\n",
    "    images = []\n",
    "    masks = []\n",
    "\n",
    "    # Sort filenames to ensure consistency\n",
    "    image_filenames = sorted(os.listdir(image_dir))\n",
    "    mask_filenames = sorted(os.listdir(mask_dir))\n",
    "\n",
    "    for image_filename in image_filenames:\n",
    "        if image_filename.endswith(\".TIF\"):\n",
    "            mask_filename = image_filename.replace(\".TIF\", \"_mask.TIF\")\n",
    "\n",
    "            if mask_filename in mask_filenames:\n",
    "                image_path = os.path.join(image_dir, image_filename)\n",
    "                mask_path = os.path.join(mask_dir, mask_filename)\n",
    "\n",
    "                print(f\"Processing Image: {image_filename}, Mask: {mask_filename}\")\n",
    "\n",
    "                img, mask = split_image_into_tiles(image_path, mask_path, tile_size)\n",
    "\n",
    "                images.extend(img)\n",
    "                masks.extend(mask)\n",
    "\n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "# Define your paths\n",
    "image_dir = \"datasets2/images\"\n",
    "mask_dir = \"datasets2/masks\"\n",
    "\n",
    "# Tile size (adjust as needed)\n",
    "tile_size = 256\n",
    "size = 256\n",
    "# Load data\n",
    "tiles_img, tiles_mask = load_data(image_dir, mask_dir, tile_size)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tiles_img, tiles_mask, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split the training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# Reshape masks\n",
    "y_train = y_train.reshape(y_train.shape + (1,))\n",
    "y_val = y_val.reshape(y_val.shape + (1,))\n",
    "y_test = y_test.reshape(y_test.shape + (1,))\n",
    "\n",
    "# Define complex VGG16 U-Net model\n",
    "def vgg16_unet_model(input_size=(size, size, 3), freeze_encoder=True):\n",
    "    # Use VGG16 as the backbone\n",
    "    vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=input_size)\n",
    "\n",
    "    # Encoder\n",
    "    encoder_output = vgg16_base.get_layer('block5_pool').output\n",
    "    \n",
    "    # Freeze the layers in the encoder\n",
    "    if freeze_encoder:\n",
    "        for layer in vgg16_base.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    # Decoder\n",
    "    x = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(encoder_output)\n",
    "    x = Concatenate()([x, vgg16_base.get_layer('block4_pool').output])\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = Concatenate()([x, vgg16_base.get_layer('block3_pool').output])\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = Concatenate()([x, vgg16_base.get_layer('block2_pool').output])\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = Concatenate()([x, vgg16_base.get_layer('block1_pool').output])\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Output layer\n",
    "    output = Conv2D(1, (1, 1), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    # Resize the output to match the size of the ground truth masks\n",
    "    output = tf.image.resize(output, (size, size), method='bilinear')\n",
    "\n",
    "    model = Model(inputs=vgg16_base.input, outputs=output)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create the VGG16 U-Net model\n",
    "vgg16_unet_model = vgg16_unet_model(input_size=(size, size, 3), freeze_encoder=True)\n",
    "\n",
    "# Learning rate schedule\n",
    "def lr_schedule(epoch):\n",
    "    initial_learning_rate = 0.0001\n",
    "    decay = 0.9\n",
    "    if epoch % 10 == 0 and epoch:\n",
    "        return initial_learning_rate * decay\n",
    "    return initial_learning_rate\n",
    "\n",
    "# Use LearningRateScheduler callback to adjust learning rate dynamically\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# Increased data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=[0.8, 1.2]\n",
    ")\n",
    "\n",
    "# callback function to stop overfitting the model\n",
    "checkpointer = ModelCheckpoint(\"best_weight_unet_vgg16_05082025.h5\", monitor=\"val_loss\", verbose=1, save_best_only=True, mode=\"min\")\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min')\n",
    "\n",
    "callbacks = [\n",
    "    earlyStopping,\n",
    "    checkpointer\n",
    "]\n",
    "\n",
    "# Train the model on the training set\n",
    "history = vgg16_unet_model.fit(datagen.flow(X_train, y_train, batch_size=32), epochs=100, validation_data=(X_val, y_val), callbacks=[lr_scheduler] + callbacks)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = vgg16_unet_model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')\n",
    "\n",
    "# Save the model\n",
    "vgg16_unet_model.save('forest_detection_model_vgg16_unet_05082025.h5')\n",
    "\n",
    "# Plot training history\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
