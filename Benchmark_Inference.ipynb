{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0687fa28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def benchmark_inference_rgb(\n",
    "    model,\n",
    "    X,                      # (N,256,256,3) in [0,255] OR [0,1]\n",
    "    batch_size=16,\n",
    "    n_tiles=1024,           # how many tiles to time\n",
    "    warmup_batches=10,\n",
    "    repeats=3,\n",
    "    pixel_size_m=30,\n",
    "    tile_size=256,\n",
    "):\n",
    "    # --- prepare data (ensure float32 in [0,1]) ---\n",
    "    Xb = X[:n_tiles].astype(np.float32)\n",
    "    if Xb.max() > 1.5:\n",
    "        Xb = Xb / 255.0\n",
    "\n",
    "    # Make a tf.data pipeline for fair GPU timing\n",
    "    ds = tf.data.Dataset.from_tensor_slices(Xb).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    # Warmup (GPU kernels, cudnn autotune, etc.)\n",
    "    for i, xb in enumerate(ds):\n",
    "        _ = model(xb, training=False)\n",
    "        if i + 1 >= warmup_batches:\n",
    "            break\n",
    "\n",
    "    # Timing\n",
    "    times = []\n",
    "    for _ in range(repeats):\n",
    "        t0 = time.perf_counter()\n",
    "        n = 0\n",
    "        for xb in ds:\n",
    "            _ = model(xb, training=False)\n",
    "            n += xb.shape[0]\n",
    "        # Make sure all queued GPU work is done before stopping timer\n",
    "      #  tf.experimental.sync_devices()\n",
    "        t1 = time.perf_counter()\n",
    "        times.append(t1 - t0)\n",
    "\n",
    "    mean_s = float(np.mean(times))\n",
    "    std_s = float(np.std(times, ddof=1)) if repeats > 1 else 0.0\n",
    "\n",
    "    sec_per_tile = mean_s / n_tiles\n",
    "    # area per tile (km^2)\n",
    "    tile_side_km = (tile_size * pixel_size_m) / 1000.0\n",
    "    area_km2 = tile_side_km * tile_side_km  # 58.9824 for 30m & 256\n",
    "    sec_per_km2 = sec_per_tile / area_km2\n",
    "    km2_per_hour = (3600.0 * area_km2) / sec_per_tile\n",
    "\n",
    "    out = {\n",
    "        \"n_tiles\": n_tiles,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"time_total_mean_s\": mean_s,\n",
    "        \"time_total_std_s\": std_s,\n",
    "        \"sec_per_tile\": sec_per_tile,\n",
    "        \"tile_area_km2\": area_km2,\n",
    "        \"sec_per_km2\": sec_per_km2,\n",
    "        \"km2_per_hour\": km2_per_hour,\n",
    "    }\n",
    "\n",
    "    print(\"\\nInference benchmark\")\n",
    "    print(f\"- tiles timed: {n_tiles}\")\n",
    "    print(f\"- batch size: {batch_size}\")\n",
    "    print(f\"- total time: {mean_s:.3f} s (Â±{std_s:.3f} over {repeats} runs)\")\n",
    "    print(f\"- sec/tile: {sec_per_tile:.6f}\")\n",
    "    print(f\"- tile area: {area_km2:.4f} km^2\")\n",
    "    print(f\"- sec/km^2: {sec_per_km2:.6f}\")\n",
    "    print(f\"- throughput: {km2_per_hour:.2f} km^2/hour\")\n",
    "\n",
    "    return out\n",
    "\n",
    "# Example call (use your X_test before preprocess scaling OR X_test/255 already):\n",
    "bench = benchmark_inference_rgb(\n",
    "    model=model,\n",
    "    X=X_test,          # your numpy test tiles\n",
    "    batch_size=16,\n",
    "    n_tiles=min(2048, X_test.shape[0]),\n",
    "    warmup_batches=10,\n",
    "    repeats=3,\n",
    "    pixel_size_m=30,\n",
    "    tile_size=256\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
