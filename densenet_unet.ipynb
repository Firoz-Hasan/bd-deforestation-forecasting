{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde726fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, Concatenate, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e756fa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
    "\n",
    "def iou_coef(y_true, y_pred, smooth=1):\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    union = tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) - intersection\n",
    "    return (intersection + smooth) / (union + smooth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdbebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split images into tiles\n",
    "def split_image_into_tiles(image_path, mask_path, tile_size, size):\n",
    "    img = tifffile.imread(image_path)\n",
    "    mask = tifffile.imread(mask_path)\n",
    "    mask = mask[:, :, 0] if len(mask.shape) == 3 else mask\n",
    "\n",
    "    tiles_img, tiles_mask = [], []\n",
    "    for x in range(0, img.shape[1], tile_size):\n",
    "        for y in range(0, img.shape[0], tile_size):\n",
    "            tile_img = img[y:y+tile_size, x:x+tile_size, :]\n",
    "            tile_mask = mask[y:y+tile_size, x:x+tile_size]\n",
    "\n",
    "            tile_img = cv2.resize(tile_img, (size, size))\n",
    "            tile_mask = cv2.resize(tile_mask, (size, size))\n",
    "            tile_mask = (tile_mask > 0).astype(np.uint8)\n",
    "\n",
    "            tiles_img.append(tile_img)\n",
    "            tiles_mask.append(tile_mask)\n",
    "\n",
    "    return np.array(tiles_img), np.array(tiles_mask)\n",
    "\n",
    "# Load dataset\n",
    "def load_data(image_dir, mask_dir, tile_size=256, size=256):\n",
    "    images, masks = [], []\n",
    "    image_filenames = sorted(os.listdir(image_dir))\n",
    "    mask_filenames = sorted(os.listdir(mask_dir))\n",
    "\n",
    "    for image_filename in image_filenames:\n",
    "        if image_filename.endswith(\".TIF\"):\n",
    "            mask_filename = image_filename.replace(\".TIF\", \"_mask.TIF\")\n",
    "            if mask_filename in mask_filenames:\n",
    "                img_path = os.path.join(image_dir, image_filename)\n",
    "                mask_path = os.path.join(mask_dir, mask_filename)\n",
    "                img, mask = split_image_into_tiles(img_path, mask_path, tile_size, size)\n",
    "                images.extend(img)\n",
    "                masks.extend(mask)\n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "# Paths\n",
    "image_dir = \"../../datasets/images\"\n",
    "mask_dir = \"../../datasets/masks\"\n",
    "size = 256\n",
    "\n",
    "# Load data\n",
    "tiles_img, tiles_mask = load_data(image_dir, mask_dir, tile_size=size, size=size)\n",
    "\n",
    "# Split sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tiles_img, tiles_mask, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# Reshape masks\n",
    "y_train = y_train[..., np.newaxis]\n",
    "y_val = y_val[..., np.newaxis]\n",
    "y_test = y_test[..., np.newaxis]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9b98ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tifffile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, Conv2DTranspose\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "# Define DenseNet U-Net model\n",
    "def densenet_unet_model(input_size=(size, size, 3), freeze_encoder=True):\n",
    "    # Use DenseNet121 as the backbone\n",
    "    densenet_base = DenseNet121(weights='imagenet', include_top=False, input_shape=input_size)\n",
    "\n",
    "    # Encoder\n",
    "    encoder_output = densenet_base.get_layer('conv5_block16_concat').output\n",
    "    \n",
    "    # Freeze the layers in the encoder\n",
    "    if freeze_encoder:\n",
    "        for layer in densenet_base.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    # Decoder\n",
    "    x = Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(encoder_output)\n",
    "    x = Concatenate()([x, densenet_base.get_layer('conv4_block24_concat').output])\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = Concatenate()([x, densenet_base.get_layer('conv3_block12_concat').output])\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = Concatenate()([x, densenet_base.get_layer('conv2_block6_concat').output])\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x)\n",
    "    x = Concatenate()([x, densenet_base.get_layer('conv1/conv').output])\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Output layer\n",
    "    output = Conv2D(1, (1, 1), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    # Resize the output to match the size of the ground truth masks\n",
    "    output = tf.image.resize(output, (size, size), method='bilinear')\n",
    "\n",
    "    model = Model(inputs=densenet_base.input, outputs=output)\n",
    "\n",
    "    #model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-4),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', dice_coef, iou_coef]\n",
    "    )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "# Usage\n",
    "size = 256\n",
    "model = densenet_unet_model(input_size=(size, size, 3), freeze_encoder=True)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9535b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LR schedule\n",
    "def lr_schedule(epoch):\n",
    "    initial_lr = 1e-4\n",
    "    decay = 0.9\n",
    "    return initial_lr * (decay ** (epoch // 10))\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(rescale=1./255,\n",
    "                             shear_range=0.2,\n",
    "                             zoom_range=0.2,\n",
    "                             horizontal_flip=True,\n",
    "                             rotation_range=20,\n",
    "                             width_shift_range=0.2,\n",
    "                             height_shift_range=0.2,\n",
    "                             brightness_range=[0.8, 1.2])\n",
    "\n",
    "# Callbacks\n",
    "checkpointer = ModelCheckpoint(\"best_densenet_unet.h5\", monitor=\"val_dice_coef\", mode=\"max\",\n",
    "                               save_best_only=True, verbose=1)\n",
    "earlyStopping = EarlyStopping(monitor=\"val_dice_coef\", patience=5, mode=\"max\", verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8bff5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=32),\n",
    "                    validation_data=(X_val/255.0, y_val),\n",
    "                    epochs=50,\n",
    "                    callbacks=[lr_scheduler, earlyStopping, checkpointer])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cf950b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "\n",
    "def bootstrap_confidence_interval(y_true, y_pred, metric_fn, n_bootstraps=50, alpha=0.95):\n",
    "    \"\"\"Bootstrap CI + std for a given metric\"\"\"\n",
    "    stats = []\n",
    "    n = len(y_true)\n",
    "    for _ in range(n_bootstraps):\n",
    "        indices = np.random.randint(0, n, n)\n",
    "        if metric_fn.__name__ == \"roc_auc_score\":  # ROC-AUC requires probs\n",
    "            stat = metric_fn(y_true[indices], y_pred[indices])\n",
    "        else:  # Binary metrics\n",
    "            stat = metric_fn(y_true[indices], y_pred[indices])\n",
    "        stats.append(stat)\n",
    "    \n",
    "    stats = np.array(stats)\n",
    "    mean_val = np.mean(stats)\n",
    "    std_val  = np.std(stats)\n",
    "    lower = np.percentile(stats, ((1 - alpha) / 2) * 100)\n",
    "    upper = np.percentile(stats, (alpha + (1 - alpha) / 2) * 100)\n",
    "    \n",
    "    return mean_val, std_val, (lower, upper)\n",
    "\n",
    "\n",
    "# --- Evaluate model ---\n",
    "loss, acc, dice, iou = model.evaluate(X_test/255.0, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}, Accuracy: {acc:.4f}, Dice: {dice:.4f}, IoU: {iou:.4f}\")\n",
    "\n",
    "# --- Predictions ---\n",
    "y_pred = model.predict(X_test/255.0)\n",
    "y_pred_bin = (y_pred > 0.5).astype(np.uint8)\n",
    "\n",
    "# Flatten\n",
    "y_true_flat = y_test.flatten()\n",
    "y_pred_flat = y_pred_bin.flatten()\n",
    "y_pred_probs = y_pred.flatten()\n",
    "\n",
    "# --- Metrics ---\n",
    "metrics = {\n",
    "    \"Accuracy\": lambda yt, yp: np.mean(yt == yp),\n",
    "    \"Precision\": lambda yt, yp: precision_score(yt, yp),\n",
    "    \"Recall\": lambda yt, yp: recall_score(yt, yp),\n",
    "    \"F1-score\": lambda yt, yp: f1_score(yt, yp),\n",
    "    \"ROC-AUC\": lambda yt, yp: roc_auc_score(yt, yp),\n",
    "    \"Dice\": lambda yt, yp: (2*np.sum(yt*yp))/(np.sum(yt)+np.sum(yp)+1e-7),\n",
    "    \"IoU\": lambda yt, yp: np.sum(yt*yp)/(np.sum(yt)+np.sum(yp)-np.sum(yt*yp)+1e-7)\n",
    "}\n",
    "\n",
    "print(\"\\nðŸ“Š Metrics with 95% Confidence Intervals:\")\n",
    "for name, fn in metrics.items():\n",
    "    if name == \"ROC-AUC\":\n",
    "        mean_val, std_val, (low, high) = bootstrap_confidence_interval(y_true_flat, y_pred_probs, fn)\n",
    "    else:\n",
    "        mean_val, std_val, (low, high) = bootstrap_confidence_interval(y_true_flat, y_pred_flat, fn)\n",
    "    print(f\"{name}: {mean_val:.4f} Â± {std_val:.4f}  (95% CI: {low:.4f} â€“ {high:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f48c5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Flatten ground truth and predictions\n",
    "y_true_flat = y_test.flatten()\n",
    "y_pred_flat = (y_pred.flatten() > 0.5).astype(int)  # threshold at 0.5\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true_flat, y_pred_flat)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "# Classification Report\n",
    "print(classification_report(y_true_flat, y_pred_flat))\n",
    "\n",
    "# Heatmap\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "            xticklabels=[\"Non-Forest\",\"Forest\"],\n",
    "            yticklabels=[\"Non-Forest\",\"Forest\"])\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f70bbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history for loss, accuracy, dice, iou\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Metrics')\n",
    "plt.title('Resnet Segmentation Training History')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0517d672",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8b7ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Epochs: 1 to 17 (early stopping at 17)\n",
    "epochs = range(1, 18)\n",
    "\n",
    "# Training metrics\n",
    "train_loss = [\n",
    "    0.5527, 0.3876, 0.3325, 0.3180, 0.3140, 0.3094, 0.3067, 0.2958, 0.3021,\n",
    "    0.2911, 0.2939, 0.2940, 0.2890, 0.2801, 0.2838, 0.2831, 0.2860\n",
    "]\n",
    "\n",
    "train_accuracy = [\n",
    "    0.7705, 0.8303, 0.8567, 0.8621, 0.8624, 0.8648, 0.8671, 0.8710, 0.8671,\n",
    "    0.8712, 0.8677, 0.8683, 0.8720, 0.8742, 0.8731, 0.8723, 0.8748\n",
    "]\n",
    "\n",
    "train_dice = [\n",
    "    0.6196, 0.7474, 0.7922, 0.8061, 0.8046, 0.8096, 0.8120, 0.8223, 0.8167,\n",
    "    0.8271, 0.8253, 0.8202, 0.8267, 0.8323, 0.8298, 0.8297, 0.8303\n",
    "]\n",
    "\n",
    "train_iou = [\n",
    "    0.4520, 0.5984, 0.6573, 0.6774, 0.6761, 0.6825, 0.6856, 0.6995, 0.6926,\n",
    "    0.7071, 0.7040, 0.6975, 0.7066, 0.7145, 0.7111, 0.7117, 0.7117\n",
    "]\n",
    "\n",
    "# Validation metrics\n",
    "val_loss = [\n",
    "    0.5907, 0.4341, 0.3285, 0.2855, 0.2707, 0.2582, 0.2762, 0.2757, 0.2792,\n",
    "    0.2456, 0.2389, 0.2173, 0.2440, 0.2383, 0.2281, 0.2203, 0.2591\n",
    "]\n",
    "\n",
    "val_accuracy = [\n",
    "    0.7914, 0.7953, 0.8303, 0.8937, 0.8900, 0.9038, 0.8832, 0.8651, 0.8852,\n",
    "    0.8923, 0.9029, 0.9078, 0.9044, 0.9029, 0.9062, 0.9088, 0.9045\n",
    "]\n",
    "\n",
    "val_dice = [\n",
    "    0.7017, 0.7694, 0.7922, 0.8099, 0.8067, 0.8197, 0.8285, 0.8105, 0.8318,\n",
    "    0.8371, 0.8443, 0.8614, 0.8433, 0.8432, 0.8533, 0.8592, 0.8261\n",
    "]\n",
    "\n",
    "val_iou = [\n",
    "    0.5427, 0.6273, 0.6574, 0.6829, 0.6781, 0.6967, 0.7098, 0.6831, 0.7149,\n",
    "    0.7215, 0.7327, 0.7583, 0.7313, 0.7309, 0.7461, 0.7551, 0.7060\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f027277",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "# Plot 1: Loss\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs, train_loss, 'bo-', label='Training Loss', linewidth=2)\n",
    "plt.plot(epochs, val_loss, 'r-o', label='Validation Loss', linewidth=2)\n",
    "plt.title('Training and Validation Loss', fontsize=14)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Accuracy\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs, train_accuracy, 'bo-', label='Training Accuracy', linewidth=2)\n",
    "plt.plot(epochs, val_accuracy, 'r-o', label='Validation Accuracy', linewidth=2)\n",
    "plt.title('Training and Validation Accuracy', fontsize=14)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Dice Coefficient\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(epochs, train_dice, 'bo-', label='Training Dice Coefficient', linewidth=2)\n",
    "plt.plot(epochs, val_dice, 'r-o', label='Validation Dice Coefficient', linewidth=2)\n",
    "plt.title('Training and Validation Dice Coefficient', fontsize=14)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Dice Coefficient')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: IoU\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(epochs, train_iou, 'bo-', label='Training IoU', linewidth=2)\n",
    "plt.plot(epochs, val_iou, 'r-o', label='Validation IoU', linewidth=2)\n",
    "plt.title('Training and Validation IoU', fontsize=14)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('IoU')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Adjust layout and show\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cb25b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, roc_auc_score\n",
    ")\n",
    "import tensorflow as tf\n",
    "\n",
    "# ==============================\n",
    "# Parameters\n",
    "# ==============================\n",
    "K = 5\n",
    "random_state = 42\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "size = 256  # image size\n",
    "\n",
    "# Normalize input images\n",
    "tiles_img_norm = tiles_img / 255.0\n",
    "# Expand mask dims if needed: (N, H, W) -> (N, H, W, 1)\n",
    "tiles_mask = tiles_mask[..., np.newaxis]\n",
    "\n",
    "# Initialize K-Fold\n",
    "kf = KFold(n_splits=K, shuffle=True, random_state=random_state)\n",
    "\n",
    "# Store metrics per fold\n",
    "metrics_per_fold = {\n",
    "    \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": [],\n",
    "    \"Dice\": [], \"mIoU\": [], \"ROC-AUC\": []\n",
    "}\n",
    "conf_matrices = []\n",
    "\n",
    "# ==============================\n",
    "# Learning Rate Scheduler\n",
    "# ==============================\n",
    "def lr_schedule(epoch):\n",
    "    lr = 1e-4\n",
    "    if epoch > 70:\n",
    "        lr *= 0.1\n",
    "    elif epoch > 50:\n",
    "        lr *= 0.5\n",
    "    return lr\n",
    "\n",
    "# ==============================\n",
    "# Start Cross-Validation\n",
    "# ==============================\n",
    "fold = 1\n",
    "for train_index, val_index in kf.split(tiles_img_norm):\n",
    "    print(f\"\\n===== Fold {fold}/{K} =====\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train_cv, X_val_cv = tiles_img_norm[train_index], tiles_img_norm[val_index]\n",
    "    y_train_cv, y_val_cv = tiles_mask[train_index], tiles_mask[val_index]\n",
    "    \n",
    "    # Data augmentation\n",
    "    datagen_cv = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        shear_range=0.2, zoom_range=0.2, horizontal_flip=True,\n",
    "        rotation_range=20, width_shift_range=0.2, height_shift_range=0.2,\n",
    "        brightness_range=[0.8, 1.2]\n",
    "    )\n",
    "    \n",
    "    # Create model (replace with your actual function)\n",
    "    model_cv = densenet_unet_model(input_size=(size, size, 3), freeze_encoder=True)\n",
    "    \n",
    "    # Compile model\n",
    "    model_cv.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Callbacks\n",
    "    lr_scheduler_cv = tf.keras.callbacks.LearningRateScheduler(lr_schedule)\n",
    "    early_stop_cv = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=5, mode='min', restore_best_weights=True, verbose=1\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    print(f\"Training Fold {fold}...\")\n",
    "    model_cv.fit(\n",
    "        datagen_cv.flow(X_train_cv, y_train_cv, batch_size=batch_size),\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_val_cv, y_val_cv),\n",
    "        callbacks=[lr_scheduler_cv, early_stop_cv],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Predict\n",
    "    y_prob = model_cv.predict(X_val_cv, verbose=0)\n",
    "    y_pred = (y_prob > 0.5).astype(np.uint8)\n",
    "    \n",
    "    # Flatten for metric computation\n",
    "    y_true_flat = y_val_cv.flatten()\n",
    "    y_pred_flat = y_pred.flatten()\n",
    "    y_prob_flat = y_prob.flatten()\n",
    "    \n",
    "    # Compute metrics\n",
    "    acc = accuracy_score(y_true_flat, y_pred_flat)\n",
    "    prec = precision_score(y_true_flat, y_pred_flat, zero_division=0)\n",
    "    rec = recall_score(y_true_flat, y_pred_flat, zero_division=0)\n",
    "    f1 = f1_score(y_true_flat, y_pred_flat, zero_division=0)\n",
    "    \n",
    "    # Dice Coefficient (same as F1 for binary, but standard in segmentation)\n",
    "    intersection = np.logical_and(y_true_flat, y_pred_flat).sum()\n",
    "    dice = 2. * intersection / (y_true_flat.sum() + y_pred_flat.sum() + 1e-8)\n",
    "    \n",
    "    # mIoU\n",
    "    union = np.logical_or(y_true_flat, y_pred_flat).sum()\n",
    "    miou = intersection / union if union > 0 else 0.0\n",
    "    \n",
    "    # ROC-AUC\n",
    "    roc = roc_auc_score(y_true_flat, y_prob_flat)\n",
    "    \n",
    "    # Store metrics\n",
    "    metrics_per_fold[\"Accuracy\"].append(acc)\n",
    "    metrics_per_fold[\"Precision\"].append(prec)\n",
    "    metrics_per_fold[\"Recall\"].append(rec)\n",
    "    metrics_per_fold[\"F1\"].append(f1)\n",
    "    metrics_per_fold[\"Dice\"].append(dice)\n",
    "    metrics_per_fold[\"mIoU\"].append(miou)\n",
    "    metrics_per_fold[\"ROC-AUC\"].append(roc)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true_flat, y_pred_flat)\n",
    "    conf_matrices.append(cm)\n",
    "    \n",
    "    # Print fold results\n",
    "    print(f\"Fold {fold} Results:\")\n",
    "    print(f\"  Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}\")\n",
    "    print(f\"  F1: {f1:.4f}, Dice: {dice:.4f}, mIoU: {miou:.4f}, ROC-AUC: {roc:.4f}\")\n",
    "    \n",
    "    fold += 1\n",
    "\n",
    "# ==============================\n",
    "# Final Results Summary\n",
    "# ==============================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"            CROSS-VALIDATION RESULTS (5-FOLD)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results_summary = {}\n",
    "for metric, values in metrics_per_fold.items():\n",
    "    mean_val = np.mean(values)\n",
    "    std_val = np.std(values)\n",
    "    ci95 = 1.96 * (std_val / np.sqrt(K))  # Approximate 95% CI\n",
    "    ci_lower = mean_val - ci95\n",
    "    ci_upper = mean_val + ci95\n",
    "    results_summary[metric] = (mean_val, std_val, ci_lower, ci_upper)\n",
    "    print(f\"{metric:<10}: {mean_val:.4f} Â± {std_val:.4f} | 95% CI: [{ci_lower:.4f}, {ci_upper:.4f}]\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ==============================\n",
    "# Per-Fold Results Table\n",
    "# ==============================\n",
    "results_df = pd.DataFrame({\n",
    "    'Fold': [f\"F{i}\" for i in range(1, K+1)],\n",
    "    'Accuracy': [f\"{v:.4f}\" for v in metrics_per_fold[\"Accuracy\"]],\n",
    "    'Precision': [f\"{v:.4f}\" for v in metrics_per_fold[\"Precision\"]],\n",
    "    'Recall': [f\"{v:.4f}\" for v in metrics_per_fold[\"Recall\"]],\n",
    "    'F1': [f\"{v:.4f}\" for v in metrics_per_fold[\"F1\"]],\n",
    "    'Dice': [f\"{v:.4f}\" for v in metrics_per_fold[\"Dice\"]],\n",
    "    'mIoU': [f\"{v:.4f}\" for v in metrics_per_fold[\"mIoU\"]],\n",
    "    'ROC-AUC': [f\"{v:.4f}\" for v in metrics_per_fold[\"ROC-AUC\"]]\n",
    "})\n",
    "print(\"\\nPer-Fold Results:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Optional: Save to CSV\n",
    "# results_df.to_csv(\"cv_per_fold_results.csv\", index=False)\n",
    "\n",
    "# ==============================\n",
    "# Plot: Metric Stability Across Folds\n",
    "# ==============================\n",
    "plt.figure(figsize=(12, 6))\n",
    "metrics_to_plot = [\"Accuracy\", \"Dice\", \"mIoU\", \"F1\", \"Recall\"]\n",
    "x_folds = np.arange(1, K+1)\n",
    "\n",
    "for metric in metrics_to_plot:\n",
    "    plt.plot(x_folds, metrics_per_fold[metric], 'o-', label=metric)\n",
    "\n",
    "plt.axhline(np.mean(metrics_per_fold[\"Dice\"]), color='gray', linestyle='--', alpha=0.7,\n",
    "            label=f\"Mean Dice = {np.mean(metrics_per_fold['Dice']):.4f}\")\n",
    "plt.xlabel(\"Fold\", fontsize=12)\n",
    "plt.ylabel(\"Score\", fontsize=12)\n",
    "plt.title(\"Cross-Validation Performance per Fold\", fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim(0.8, 1.0)\n",
    "plt.xticks(x_folds)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ==============================\n",
    "# Average Confusion Matrix\n",
    "# ==============================\n",
    "avg_cm = np.mean(conf_matrices, axis=0)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(avg_cm, annot=True, fmt=\".0f\", cmap=\"Blues\", cbar=True,\n",
    "            xticklabels=[\"Non-Forest\", \"Forest\"],\n",
    "            yticklabels=[\"Non-Forest\", \"Forest\"], square=True)\n",
    "plt.xlabel(\"Predicted Label\", fontsize=12)\n",
    "plt.ylabel(\"True Label\", fontsize=12)\n",
    "plt.title(\"Average Confusion Matrix (5-Fold CV)\", fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optional: Save confusion matrix\n",
    "# plt.savefig(\"avg_confusion_matrix_cv.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b7cb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15daf7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, roc_auc_score\n",
    ")\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# ==============================\n",
    "# Parameters\n",
    "# ==============================\n",
    "K = 5\n",
    "random_state = 42\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "size = 256  # image size\n",
    "\n",
    "# Normalize input images\n",
    "tiles_img_norm = tiles_img / 255.0\n",
    "# Expand mask dims: (N, H, W) -> (N, H, W, 1)\n",
    "tiles_mask = tiles_mask[..., np.newaxis]\n",
    "\n",
    "# Initialize K-Fold\n",
    "kf = KFold(n_splits=K, shuffle=True, random_state=random_state)\n",
    "\n",
    "# Store metrics per fold\n",
    "metrics_per_fold = {\n",
    "    \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": [],\n",
    "    \"Dice\": [], \"mIoU\": [], \"ROC-AUC\": []\n",
    "}\n",
    "conf_matrices = []\n",
    "\n",
    "# ==============================\n",
    "# Dice Coefficient Metric\n",
    "# ==============================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = tf.cast(tf.reshape(y_true, [-1]), tf.float32)\n",
    "    y_pred_f = tf.cast(tf.reshape(y_pred, [-1]), tf.float32)\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + 1e-8) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + 1e-8)\n",
    "# ==============================\n",
    "# Learning Rate Scheduler (on Dice)\n",
    "# ==============================\n",
    "lr_scheduler_cv = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_dice_coef',\n",
    "    factor=0.5,\n",
    "    patience=3,\n",
    "    mode='max',\n",
    "    min_lr=1e-7,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ==============================\n",
    "# Start Cross-Validation\n",
    "# ==============================\n",
    "fold = 1\n",
    "for train_index, val_index in kf.split(tiles_img_norm):\n",
    "    print(f\"\\n===== Fold {fold}/{K} =====\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train_cv, X_val_cv = tiles_img_norm[train_index], tiles_img_norm[val_index]\n",
    "    y_train_cv, y_val_cv = tiles_mask[train_index], tiles_mask[val_index]\n",
    "    \n",
    "    # Data augmentation\n",
    "    datagen_cv = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        shear_range=0.2, zoom_range=0.2, horizontal_flip=True,\n",
    "        rotation_range=20, width_shift_range=0.2, height_shift_range=0.2,\n",
    "        brightness_range=[0.8, 1.2]\n",
    "    )\n",
    "    \n",
    "    # Create model (replace with your actual function)\n",
    "    model_cv = densenet_unet_model(input_size=(size, size, 3), freeze_encoder=True)\n",
    "    \n",
    "    # Compile model with Dice as metric\n",
    "    model_cv.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy', dice_coef]\n",
    "    )\n",
    "    \n",
    "    # Callbacks: Early stopping and checkpoint on Dice\n",
    "    early_stop_cv = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_dice_coef',\n",
    "        patience=5,\n",
    "        mode='max',\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "        f'best_densenet_unet_fold_{fold}.h5',\n",
    "        monitor='val_dice_coef',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    print(f\"Training Fold {fold}...\")\n",
    "    model_cv.fit(\n",
    "        datagen_cv.flow(X_train_cv, y_train_cv, batch_size=batch_size),\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_val_cv, y_val_cv),\n",
    "        callbacks=[lr_scheduler_cv, early_stop_cv, model_checkpoint],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Predict\n",
    "    y_prob = model_cv.predict(X_val_cv, verbose=0)\n",
    "    y_pred = (y_prob > 0.5).astype(np.uint8)\n",
    "    \n",
    "    # Flatten for metric computation\n",
    "    y_true_flat = y_val_cv.flatten()\n",
    "    y_pred_flat = y_pred.flatten()\n",
    "    y_prob_flat = y_prob.flatten()\n",
    "    \n",
    "    # Compute metrics\n",
    "    acc = accuracy_score(y_true_flat, y_pred_flat)\n",
    "    prec = precision_score(y_true_flat, y_pred_flat, zero_division=0)\n",
    "    rec = recall_score(y_true_flat, y_pred_flat, zero_division=0)\n",
    "    f1 = f1_score(y_true_flat, y_pred_flat, zero_division=0)\n",
    "    \n",
    "    # Dice Coefficient\n",
    "    intersection = np.logical_and(y_true_flat, y_pred_flat).sum()\n",
    "    dice = 2. * intersection / (y_true_flat.sum() + y_pred_flat.sum() + 1e-8)\n",
    "    \n",
    "    # mIoU\n",
    "    union = np.logical_or(y_true_flat, y_pred_flat).sum()\n",
    "    miou = intersection / union if union > 0 else 0.0\n",
    "    \n",
    "    # ROC-AUC\n",
    "    roc = roc_auc_score(y_true_flat, y_prob_flat)\n",
    "    \n",
    "    # Store metrics\n",
    "    metrics_per_fold[\"Accuracy\"].append(acc)\n",
    "    metrics_per_fold[\"Precision\"].append(prec)\n",
    "    metrics_per_fold[\"Recall\"].append(rec)\n",
    "    metrics_per_fold[\"F1\"].append(f1)\n",
    "    metrics_per_fold[\"Dice\"].append(dice)\n",
    "    metrics_per_fold[\"mIoU\"].append(miou)\n",
    "    metrics_per_fold[\"ROC-AUC\"].append(roc)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_true_flat, y_pred_flat)\n",
    "    conf_matrices.append(cm)\n",
    "    \n",
    "    # Print fold results\n",
    "    print(f\"Fold {fold} Results:\")\n",
    "    print(f\"  Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}\")\n",
    "    print(f\"  F1: {f1:.4f}, Dice: {dice:.4f}, mIoU: {miou:.4f}, ROC-AUC: {roc:.4f}\")\n",
    "    \n",
    "    fold += 1\n",
    "\n",
    "# ==============================\n",
    "# Final Results Summary\n",
    "# ==============================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"            CROSS-VALIDATION RESULTS (5-FOLD)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results_summary = {}\n",
    "for metric, values in metrics_per_fold.items():\n",
    "    mean_val = np.mean(values)\n",
    "    std_val = np.std(values)\n",
    "    ci95 = 1.96 * (std_val / np.sqrt(K))  # Approximate 95% CI\n",
    "    ci_lower = mean_val - ci95\n",
    "    ci_upper = mean_val + ci95\n",
    "    results_summary[metric] = (mean_val, std_val, ci_lower, ci_upper)\n",
    "    print(f\"{metric:<10}: {mean_val:.4f} Â± {std_val:.4f} | 95% CI: [{ci_lower:.4f}, {ci_upper:.4f}]\")\n",
    "\n",
    "print(\"=\"*70)\n",
    "\n",
    "# ==============================\n",
    "# Per-Fold Results Table\n",
    "# ==============================\n",
    "results_df = pd.DataFrame({\n",
    "    'Fold': [f\"F{i}\" for i in range(1, K+1)],\n",
    "    'Accuracy': [f\"{v:.4f}\" for v in metrics_per_fold[\"Accuracy\"]],\n",
    "    'Precision': [f\"{v:.4f}\" for v in metrics_per_fold[\"Precision\"]],\n",
    "    'Recall': [f\"{v:.4f}\" for v in metrics_per_fold[\"Recall\"]],\n",
    "    'F1': [f\"{v:.4f}\" for v in metrics_per_fold[\"F1\"]],\n",
    "    'Dice': [f\"{v:.4f}\" for v in metrics_per_fold[\"Dice\"]],\n",
    "    'mIoU': [f\"{v:.4f}\" for v in metrics_per_fold[\"mIoU\"]],\n",
    "    'ROC-AUC': [f\"{v:.4f}\" for v in metrics_per_fold[\"ROC-AUC\"]]\n",
    "})\n",
    "print(\"\\nPer-Fold Results:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Optional: Save to CSV\n",
    "# results_df.to_csv(\"cv_per_fold_results.csv\", index=False)\n",
    "\n",
    "# ==============================\n",
    "# Plot: Metric Stability Across Folds\n",
    "# ==============================\n",
    "plt.figure(figsize=(12, 6))\n",
    "metrics_to_plot = [\"Accuracy\", \"Dice\", \"mIoU\", \"F1\", \"Recall\"]\n",
    "x_folds = np.arange(1, K+1)\n",
    "\n",
    "for metric in metrics_to_plot:\n",
    "    plt.plot(x_folds, metrics_per_fold[metric], 'o-', label=metric)\n",
    "\n",
    "plt.axhline(np.mean(metrics_per_fold[\"Dice\"]), color='gray', linestyle='--', alpha=0.7,\n",
    "            label=f\"Mean Dice = {np.mean(metrics_per_fold['Dice']):.4f}\")\n",
    "plt.xlabel(\"Fold\", fontsize=12)\n",
    "plt.ylabel(\"Score\", fontsize=12)\n",
    "plt.title(\"Cross-Validation Performance per Fold\", fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim(0.8, 1.0)\n",
    "plt.xticks(x_folds)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ==============================\n",
    "# Average Confusion Matrix\n",
    "# ==============================\n",
    "avg_cm = np.mean(conf_matrices, axis=0)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(avg_cm, annot=True, fmt=\".0f\", cmap=\"Blues\", cbar=True,\n",
    "            xticklabels=[\"Non-Forest\", \"Forest\"],\n",
    "            yticklabels=[\"Non-Forest\", \"Forest\"], square=True)\n",
    "plt.xlabel(\"Predicted Label\", fontsize=12)\n",
    "plt.ylabel(\"True Label\", fontsize=12)\n",
    "plt.title(\"Average Confusion Matrix (5-Fold CV)\", fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optional: Save results\n",
    "# plt.savefig(\"avg_confusion_matrix_cv.png\", dpi=300, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bf3fd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfed1edc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7137b707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a358967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e0ef58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd47e134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e297ff90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
