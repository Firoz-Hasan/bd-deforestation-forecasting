{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c03a9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.layers import (Input, Conv2D, Conv2DTranspose,\n",
    "                                     Concatenate, BatchNormalization,\n",
    "                                     Activation, Lambda)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import (ModelCheckpoint, EarlyStopping,\n",
    "                                        LearningRateScheduler)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. Data‑loading stub  ⇢  REPLACE with real loader\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. DenseNet121‑U‑Net model\n",
    "# ------------------------------------------------------------------\n",
    "def densenet121_unet(input_size=(256, 256, 3),\n",
    "                     freeze_encoder=True,\n",
    "                     decoder_filters=(512, 256, 128, 64),\n",
    "                     upsample_mode=\"transpose\",\n",
    "                     final_activation=\"sigmoid\"):\n",
    "    \"\"\"\n",
    "    Build a DenseNet121‑based U‑Net.\n",
    "    \"\"\"\n",
    "    # ---- Encoder --------------------------------------------------\n",
    "    dense = DenseNet121(weights=\"imagenet\",\n",
    "                        include_top=False,\n",
    "                        input_tensor=Input(shape=input_size))\n",
    "\n",
    "    # DenseNet feature maps for skip connections\n",
    "    skip_names = [\n",
    "        \"conv1/relu\",      #  64×64×64    (DenseNet downsamples early)\n",
    "        \"pool2_relu\",      #  32×32×128\n",
    "        \"pool3_relu\",      #  16×16×256\n",
    "        \"pool4_relu\"       #   8×8×512\n",
    "    ]\n",
    "    encoder_output = dense.output            # 8×8×1024 (after final dense block)\n",
    "\n",
    "    if freeze_encoder:\n",
    "        for layer in dense.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    # ---- Decoder helper ------------------------------------------\n",
    "    def upsample(x, filters, name):\n",
    "        if upsample_mode == \"transpose\":\n",
    "            return Conv2DTranspose(filters, 2, strides=2, padding=\"same\",\n",
    "                                   name=f\"{name}_up\")(x)\n",
    "        # bilinear upsample + conv\n",
    "        x = Lambda(lambda t: tf.image.resize(t,\n",
    "                                             (t.shape[1] * 2, t.shape[2] * 2),\n",
    "                                             method=\"bilinear\"),\n",
    "                   name=f\"{name}_resize\")(x)\n",
    "        return Conv2D(filters, 3, padding=\"same\", name=f\"{name}_conv\")(x)\n",
    "\n",
    "    # ---- Decoder -------------------------------------------------\n",
    "    x = encoder_output\n",
    "    for i, (skip_name, f) in enumerate(zip(reversed(skip_names), decoder_filters), 1):\n",
    "        x = upsample(x, f, name=f\"dec{i}\")\n",
    "        skip = dense.get_layer(skip_name).output\n",
    "        x = Concatenate(name=f\"concat{i}\")([x, skip])\n",
    "\n",
    "        # Two conv‑BN‑ReLU layers\n",
    "        for j in range(2):\n",
    "            x = Conv2D(f, 3, padding=\"same\", name=f\"dec{i}_conv{j+1}\")(x)\n",
    "            x = BatchNormalization(name=f\"dec{i}_bn{j+1}\")(x)\n",
    "            x = Activation(\"relu\", name=f\"dec{i}_act{j+1}\")(x)\n",
    "\n",
    "    # Final upsample to 256×256\n",
    "    x = upsample(x, decoder_filters[-1] // 2, name=\"dec_final\")\n",
    "\n",
    "    mask = Conv2D(1, 1, activation=final_activation,\n",
    "                  padding=\"same\", name=\"mask\")(x)\n",
    "\n",
    "    mask = Lambda(lambda t: tf.image.resize(t,\n",
    "                                            (input_size[0], input_size[1]),\n",
    "                                            method=\"bilinear\"),\n",
    "                  name=\"identity_resize\")(mask)\n",
    "\n",
    "    model = Model(inputs=dense.input, outputs=mask, name=\"DenseNet121_UNet\")\n",
    "    model.compile(optimizer=\"adam\",\n",
    "                  loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. Paths and hyper‑parameters\n",
    "# ------------------------------------------------------------------\n",
    "IMAGE_DIR = \"datasets2/images\"\n",
    "MASK_DIR  = \"datasets2/masks\"\n",
    "TILE_SIZE = 256\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "size = 256\n",
    "# ------------------------------------------------------------------\n",
    "# 4. Prepare data\n",
    "# ------------------------------------------------------------------\n",
    "X, y = load_data(IMAGE_DIR, MASK_DIR, TILE_SIZE)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# Add channel dimension to masks\n",
    "y_train = y_train[..., np.newaxis]\n",
    "y_val   = y_val[..., np.newaxis]\n",
    "y_test  = y_test[..., np.newaxis]\n",
    "\n",
    "# Data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=[0.8, 1.2]\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5. Callbacks\n",
    "# ------------------------------------------------------------------\n",
    "def lr_schedule(epoch):\n",
    "    base_lr = 1e-4\n",
    "    decay   = 0.9\n",
    "    return base_lr * (decay ** (epoch // 10))\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "checkpointer  = ModelCheckpoint(\"best_densenet_unet.h5\",\n",
    "                                monitor=\"val_loss\",\n",
    "                                save_best_only=True,\n",
    "                                mode=\"min\")\n",
    "\n",
    "early_stop   = EarlyStopping(monitor=\"val_loss\",\n",
    "                             patience=5,\n",
    "                             mode=\"min\",\n",
    "                             verbose=1)\n",
    "\n",
    "callbacks = [lr_scheduler, checkpointer, early_stop]\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 6. Build and train model\n",
    "# ------------------------------------------------------------------\n",
    "model = densenet121_unet(input_size=(TILE_SIZE, TILE_SIZE, 3),\n",
    "                         freeze_encoder=True)\n",
    "\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 7. Evaluate and save\n",
    "# ------------------------------------------------------------------\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f} | Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "model.save(\"forest_detection_densenet_unet_full.h5\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 8. Plot losses\n",
    "# ------------------------------------------------------------------\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history[\"loss\"],     label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"densenet_unet_training_curve.png\")\n",
    "plt.close()\n",
    "print(\"Training curve saved to densenet_unet_training_curve.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8b84ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load_model('best_densenet_unet.h5')\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "# Threshold the predictions to get binary values (0 or 1)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Flatten the arrays for metrics calculation\n",
    "y_test_flat = y_test.flatten()\n",
    "y_pred_flat = y_pred_binary.flatten()\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = accuracy_score(y_test_flat, y_pred_flat)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate and print F1 score\n",
    "f1 = f1_score(y_test_flat, y_pred_flat)\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "# Calculate and print precision\n",
    "precision = precision_score(y_test_flat, y_pred_flat)\n",
    "print(f'Precision: {precision:.4f}')\n",
    "\n",
    "# Calculate and print recall\n",
    "recall = recall_score(y_test_flat, y_pred_flat)\n",
    "print(f'Recall: {recall:.4f}')\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_flat, y_pred_flat)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate mean intersection over union (mIoU)\n",
    "intersection = np.sum(np.logical_and(y_test_flat, y_pred_flat))\n",
    "union = np.sum(np.logical_or(y_test_flat, y_pred_flat))\n",
    "miou = intersection / union\n",
    "print(f'Mean Intersection over Union (mIoU): {miou:.4f}')\n",
    "\n",
    "\n",
    "# --- AUC‑ROC --------------------------------------------------------------\n",
    "# 1‑D‑ify the ground‑truth mask and the model’s probability output\n",
    "y_test_prob = y_test.flatten()\n",
    "y_pred_prob = y_pred.flatten()       # <‑‑ raw probabilities, NOT thresholded\n",
    "\n",
    "# Compute AUC\n",
    "auc = roc_auc_score(y_test_prob, y_pred_prob)\n",
    "print(f'AUC‑ROC: {auc:.4f}')\n",
    "\n",
    "# Optional: plot the ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test_prob, y_pred_prob)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, linewidth=2, label=f'ROC curve (AUC = {auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', linewidth=1)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
