{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812fa23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tifffile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization, Conv2DTranspose\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ---- CONFIG ---- #\n",
    "tile_size = 256\n",
    "size = 256\n",
    "image_dir = \"datasets2/images\"\n",
    "mask_dir = \"datasets2/masks\"\n",
    "\n",
    "# ---- Function to split large image into tiles ---- #\n",
    "def split_image_into_tiles(image_path, mask_path, tile_size):\n",
    "    img = tifffile.imread(image_path)\n",
    "    mask = tifffile.imread(mask_path)\n",
    "    mask = mask[:, :, 0] if len(mask.shape) == 3 else mask\n",
    "\n",
    "    tiles_img = []\n",
    "    tiles_mask = []\n",
    "\n",
    "    for x in range(0, img.shape[1], tile_size):\n",
    "        for y in range(0, img.shape[0], tile_size):\n",
    "            tile_img = img[y:y+tile_size, x:x+tile_size, :] if len(img.shape) == 3 else img[y:y+tile_size, x:x+tile_size]\n",
    "            tile_mask = mask[y:y+tile_size, x:x+tile_size]\n",
    "\n",
    "            tile_img = cv2.resize(tile_img, (size, size))\n",
    "            tile_mask = cv2.resize(tile_mask, (size, size))\n",
    "            tile_mask = (tile_mask > 0).astype(np.uint8)\n",
    "\n",
    "            tiles_img.append(tile_img)\n",
    "            tiles_mask.append(tile_mask)\n",
    "\n",
    "    # Padding to form square grid\n",
    "    num_tiles = len(tiles_img)\n",
    "    perfect_square_size = int(np.ceil(np.sqrt(num_tiles)))\n",
    "    total_tiles_needed = perfect_square_size**2\n",
    "    num_tiles_to_add = total_tiles_needed - num_tiles\n",
    "\n",
    "    for _ in range(num_tiles_to_add):\n",
    "        tiles_img.append(np.zeros((size, size, img.shape[2]), dtype=np.uint8))\n",
    "        tiles_mask.append(np.zeros((size, size), dtype=np.uint8))\n",
    "\n",
    "    return np.array(tiles_img), np.array(tiles_mask)\n",
    "\n",
    "# ---- Load all image-mask tiles ---- #\n",
    "def load_data(image_dir, mask_dir, tile_size):\n",
    "    images, masks = [], []\n",
    "    image_filenames = sorted(os.listdir(image_dir))\n",
    "    mask_filenames = sorted(os.listdir(mask_dir))\n",
    "\n",
    "    for image_filename in image_filenames:\n",
    "        if image_filename.endswith(\".TIF\"):\n",
    "            mask_filename = image_filename.replace(\".TIF\", \"_mask.TIF\")\n",
    "            if mask_filename in mask_filenames:\n",
    "                img_path = os.path.join(image_dir, image_filename)\n",
    "                mask_path = os.path.join(mask_dir, mask_filename)\n",
    "                img_tiles, mask_tiles = split_image_into_tiles(img_path, mask_path, tile_size)\n",
    "                images.extend(img_tiles)\n",
    "                masks.extend(mask_tiles)\n",
    "\n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "# ---- Load and prepare dataset ---- #\n",
    "tiles_img, tiles_mask = load_data(image_dir, mask_dir, tile_size)\n",
    "X_train, X_test, y_train, y_test = train_test_split(tiles_img, tiles_mask, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# Reshape masks to (H, W, 1)\n",
    "y_train = y_train[..., np.newaxis]\n",
    "y_val = y_val[..., np.newaxis]\n",
    "y_test = y_test[..., np.newaxis]\n",
    "\n",
    "# ---- Define AlexNet-style Segmentation Model ---- #\n",
    "def alexnet_segmentation_model(input_size=(256, 256, 3)):\n",
    "    inputs = Input(shape=input_size)\n",
    "\n",
    "    # Encoder (AlexNet-style)\n",
    "    x = Conv2D(96, (11, 11), strides=4, padding='same', activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((3, 3), strides=2, padding='same')(x)\n",
    "\n",
    "    x = Conv2D(256, (5, 5), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((3, 3), strides=2, padding='same')(x)\n",
    "\n",
    "    x = Conv2D(384, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(384, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((3, 3), strides=2, padding='same')(x)\n",
    "\n",
    "    # Decoder (Upsampling only, no skip connections)\n",
    "    x = Conv2DTranspose(256, (3, 3), strides=2, padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2DTranspose(128, (3, 3), strides=2, padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2DTranspose(64, (3, 3), strides=2, padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Conv2DTranspose(32, (3, 3), strides=2, padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    output = Conv2D(1, (1, 1), activation='sigmoid')(x)\n",
    "\n",
    "    # Resize to match ground truth\n",
    "    output = tf.image.resize(output, (input_size[0], input_size[1]), method='bilinear')\n",
    "\n",
    "    model = Model(inputs, output)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "# ---- Build Model ---- #\n",
    "alexnet_model = alexnet_segmentation_model(input_size=(size, size, 3))\n",
    "\n",
    "# ---- Learning Rate Schedule ---- #\n",
    "def lr_schedule(epoch):\n",
    "    initial_lr = 0.0001\n",
    "    decay = 0.9\n",
    "    return initial_lr * (decay ** (epoch // 10))\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "# ---- Callbacks ---- #\n",
    "checkpointer = ModelCheckpoint(\"alexnet_segmentation_best.h5\", monitor=\"val_loss\", save_best_only=True, verbose=1)\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1)\n",
    "\n",
    "# ---- Data Augmentation ---- #\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=[0.8, 1.2]\n",
    ")\n",
    "\n",
    "# ---- Train Model ---- #\n",
    "history = alexnet_model.fit(\n",
    "    datagen.flow(X_train, y_train, batch_size=32),\n",
    "    epochs=100,\n",
    "    validation_data=(X_val / 255.0, y_val),\n",
    "    callbacks=[lr_scheduler, checkpointer, earlyStopping]\n",
    ")\n",
    "\n",
    "# ---- Evaluate Model ---- #\n",
    "loss, accuracy = alexnet_model.evaluate(X_test / 255.0, y_test)\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# ---- Save Final Model ---- #\n",
    "alexnet_model.save(\"alexnet_segmentation_model_final.h5\")\n",
    "\n",
    "# ---- Plot Training History ---- #\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.title(\"AlexNet Segmentation Training History\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd0fe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score\n",
    ")\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load_model('alexnet_segmentation_best.h5')\n",
    "\n",
    "# Predict probabilities on the test set\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "# Threshold the predictions to get binary values (0 or 1)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Flatten arrays for metric calculations\n",
    "y_test_flat = y_test.flatten()\n",
    "y_pred_flat = y_pred_binary.flatten()\n",
    "y_pred_prob_flat = y_pred.flatten()  # Keep raw probabilities for ROC-AUC\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test_flat, y_pred_flat)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test_flat, y_pred_flat)\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test_flat, y_pred_flat)\n",
    "print(f'Precision: {precision:.4f}')\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test_flat, y_pred_flat)\n",
    "print(f'Recall: {recall:.4f}')\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test_flat, y_pred_flat)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "# Mean Intersection over Union (mIoU)\n",
    "intersection = np.sum(np.logical_and(y_test_flat, y_pred_flat))\n",
    "union = np.sum(np.logical_or(y_test_flat, y_pred_flat))\n",
    "miou = intersection / union\n",
    "print(f'Mean Intersection over Union (mIoU): {miou:.4f}')\n",
    "\n",
    "# ROC-AUC Score\n",
    "roc_auc = roc_auc_score(y_test_flat, y_pred_prob_flat)\n",
    "print(f'ROC-AUC Score: {roc_auc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
