{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aeb29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Assuming dice_coef and iou_coef are already defined functions\n",
    "\n",
    "# Parameters\n",
    "K = 5\n",
    "random_state = 42\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "size = 256\n",
    "\n",
    "# Normalize all images once to avoid repeated division\n",
    "tiles_img_norm = tiles_img / 255.0\n",
    "tiles_mask = tiles_mask[..., np.newaxis]\n",
    "\n",
    "# Cross-validation setup\n",
    "kf = KFold(n_splits=K, shuffle=True, random_state=random_state)\n",
    "\n",
    "# Arrays to store evaluation metrics\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "val_dices = []\n",
    "val_ious = []\n",
    "\n",
    "fold = 1\n",
    "for train_index, val_index in kf.split(tiles_img_norm):\n",
    "    print(f\"\\n===== Fold {fold}/{K} =====\")\n",
    "    \n",
    "    # Split the data\n",
    "    X_train_cv, X_val_cv = tiles_img_norm[train_index], tiles_img_norm[val_index]\n",
    "    y_train_cv, y_val_cv = tiles_mask[train_index], tiles_mask[val_index]\n",
    "\n",
    "    # Data augmentation\n",
    "    datagen_cv = ImageDataGenerator(\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        brightness_range=[0.8, 1.2]\n",
    "    )\n",
    "\n",
    "    # Create model\n",
    "    model_cv = alexnet_segmentation_model(input_size=(size, size, 3), freeze_encoder=True)\n",
    "\n",
    "    # Callbacks\n",
    "    lr_scheduler_cv = LearningRateScheduler(lr_schedule)\n",
    "    early_stop_cv = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min')\n",
    "    \n",
    "    # Train\n",
    "    history_cv = model_cv.fit(\n",
    "        datagen_cv.flow(X_train_cv, y_train_cv, batch_size=batch_size),\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_val_cv, y_val_cv),\n",
    "        callbacks=[lr_scheduler_cv, early_stop_cv],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Evaluate\n",
    "    loss, accuracy, dice, iou = model_cv.evaluate(X_val_cv, y_val_cv, verbose=0)\n",
    "    val_losses.append(loss)\n",
    "    val_accuracies.append(accuracy)\n",
    "    val_dices.append(dice)\n",
    "    val_ious.append(iou)\n",
    "\n",
    "    print(f\"Fold {fold} — Loss: {loss:.4f}, Acc: {accuracy:.4f}, Dice: {dice:.4f}, IoU: {iou:.4f}\")\n",
    "\n",
    "    fold += 1\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n==== Cross-validation results ====\")\n",
    "print(f\"Avg Accuracy: {np.mean(val_accuracies):.4f} ± {np.std(val_accuracies):.4f}\")\n",
    "print(f\"Avg Dice:     {np.mean(val_dices):.4f} ± {np.std(val_dices):.4f}\")\n",
    "print(f\"Avg IoU:      {np.mean(val_ious):.4f} ± {np.std(val_ious):.4f}\")\n",
    "print(f\"Avg Loss:     {np.mean(val_losses):.4f} ± {np.std(val_losses):.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
