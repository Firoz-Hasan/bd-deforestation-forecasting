{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14ec45cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, Concatenate, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1cbc4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a03122c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to split an image into tiles\n",
    "def split_image_into_tiles(image_path, mask_path, tile_size):\n",
    "    img = tifffile.imread(image_path)\n",
    "    mask = tifffile.imread(mask_path)\n",
    "    mask = mask[:, :, 0] if len(mask.shape) == 3 else mask\n",
    "    print(f\"Original Image Dimensions: {img.shape}\")\n",
    "    tiles_img = []\n",
    "    tiles_mask = []\n",
    "\n",
    "    for x in range(0, img.shape[1], tile_size):\n",
    "        for y in range(0, img.shape[0], tile_size):\n",
    "            tile_img = img[y:y+tile_size, x:x+tile_size, :] if len(img.shape) == 3 else img[y:y+tile_size, x:x+tile_size]\n",
    "            tile_mask = mask[y:y+tile_size, x:x+tile_size]\n",
    "\n",
    "            # Resize to the desired size\n",
    "            tile_img = cv2.resize(tile_img, (size, size))\n",
    "            tile_mask = cv2.resize(tile_mask, (size, size))\n",
    "            tile_mask = (tile_mask > 0).astype(np.uint8)\n",
    "\n",
    "            tiles_img.append(tile_img)\n",
    "            tiles_mask.append(tile_mask)\n",
    "\n",
    "    # Calculate the number of tiles needed to form a perfect square\n",
    "    num_tiles = len(tiles_img)\n",
    "    perfect_square_size = int(np.ceil(np.sqrt(num_tiles)))\n",
    "    total_tiles_needed = perfect_square_size**2\n",
    "    num_tiles_to_add = total_tiles_needed - num_tiles\n",
    "\n",
    "    # Pad the list of tiles with zeros\n",
    "    for _ in range(num_tiles_to_add):\n",
    "        tiles_img.append(np.zeros((size, size, img.shape[2]), dtype=np.uint8))\n",
    "        tiles_mask.append(np.zeros((size, size), dtype=np.uint8))\n",
    "\n",
    "    tiles_img = np.array(tiles_img)\n",
    "    tiles_mask = np.array(tiles_mask)\n",
    "\n",
    "    return tiles_img, tiles_mask\n",
    "\n",
    "# Function to load data\n",
    "def load_data(image_dir, mask_dir, tile_size):\n",
    "    images = []\n",
    "    masks = []\n",
    "\n",
    "    # Sort filenames to ensure consistency\n",
    "    image_filenames = sorted(os.listdir(image_dir))\n",
    "    mask_filenames = sorted(os.listdir(mask_dir))\n",
    "\n",
    "    for image_filename in image_filenames:\n",
    "        if image_filename.endswith(\".TIF\"):\n",
    "            mask_filename = image_filename.replace(\".TIF\", \"_mask.TIF\")\n",
    "\n",
    "            if mask_filename in mask_filenames:\n",
    "                image_path = os.path.join(image_dir, image_filename)\n",
    "                mask_path = os.path.join(mask_dir, mask_filename)\n",
    "\n",
    "                print(f\"Processing Image: {image_filename}, Mask: {mask_filename}\")\n",
    "\n",
    "                img, mask = split_image_into_tiles(image_path, mask_path, tile_size)\n",
    "\n",
    "                images.extend(img)\n",
    "                masks.extend(mask)\n",
    "\n",
    "    return np.array(images), np.array(masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "139382a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Image: 2.TIF, Mask: 2_mask.TIF\n",
      "Original Image Dimensions: (7151, 7941, 3)\n",
      "Epoch 1/100\n",
      "21/21 [==============================] - ETA: 0s - loss: 0.5415 - accuracy: 0.7652"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Firoz\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21/21 [==============================] - 154s 7s/step - loss: 0.5415 - accuracy: 0.7652 - val_loss: 2.4597 - val_accuracy: 0.7067 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 156s 7s/step - loss: 0.3703 - accuracy: 0.8730 - val_loss: 1.9438 - val_accuracy: 0.8568 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 159s 8s/step - loss: 0.3122 - accuracy: 0.8824 - val_loss: 1.9083 - val_accuracy: 0.8751 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 155s 7s/step - loss: 0.2764 - accuracy: 0.8859 - val_loss: 1.9355 - val_accuracy: 0.8706 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 155s 7s/step - loss: 0.2573 - accuracy: 0.8914 - val_loss: 1.8949 - val_accuracy: 0.8733 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 154s 7s/step - loss: 0.2553 - accuracy: 0.8884 - val_loss: 1.9207 - val_accuracy: 0.8796 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 154s 7s/step - loss: 0.2571 - accuracy: 0.8875 - val_loss: 2.1226 - val_accuracy: 0.7097 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 154s 7s/step - loss: 0.2334 - accuracy: 0.8958 - val_loss: 2.1936 - val_accuracy: 0.7137 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 154s 7s/step - loss: 0.2369 - accuracy: 0.8961 - val_loss: 1.8561 - val_accuracy: 0.8801 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 154s 7s/step - loss: 0.2308 - accuracy: 0.8968 - val_loss: 1.8925 - val_accuracy: 0.8747 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 154s 7s/step - loss: 0.2310 - accuracy: 0.8940 - val_loss: 1.8499 - val_accuracy: 0.8789 - lr: 9.0000e-05\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 154s 7s/step - loss: 0.2351 - accuracy: 0.8899 - val_loss: 1.8692 - val_accuracy: 0.8773 - lr: 9.0000e-05\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 153s 7s/step - loss: 0.2298 - accuracy: 0.8973 - val_loss: 1.8962 - val_accuracy: 0.8722 - lr: 9.0000e-05\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 154s 7s/step - loss: 0.2244 - accuracy: 0.8993 - val_loss: 1.8843 - val_accuracy: 0.8734 - lr: 9.0000e-05\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 192s 9s/step - loss: 0.2245 - accuracy: 0.8994 - val_loss: 2.0017 - val_accuracy: 0.8664 - lr: 9.0000e-05\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 333s 16s/step - loss: 0.2236 - accuracy: 0.8982 - val_loss: 2.0532 - val_accuracy: 0.8641 - lr: 9.0000e-05\n",
      "Epoch 16: early stopping\n",
      "6/6 [==============================] - 37s 6s/step - loss: 1.9132 - accuracy: 0.8665\n",
      "Test Loss: 1.9132 | Test Accuracy: 0.8665\n",
      "Training curve saved to resnet_unet_training_curve.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import (Input, Conv2D, Conv2DTranspose,\n",
    "                                     Concatenate, BatchNormalization,\n",
    "                                     Activation, Lambda)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import (ModelCheckpoint, EarlyStopping,\n",
    "                                        LearningRateScheduler)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. Data‑loading stub (⇢ REPLACE with real loader)\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. ResNet50‑U‑Net construction\n",
    "# ------------------------------------------------------------------\n",
    "def resnet50_unet(input_size=(256, 256, 3),\n",
    "                  freeze_encoder=True,\n",
    "                  decoder_filters=(512, 256, 128, 64),\n",
    "                  upsample_mode=\"transpose\",\n",
    "                  final_activation=\"sigmoid\"):\n",
    "    \"\"\"Return a compiled ResNet50‑U‑Net Keras model.\"\"\"\n",
    "    # --- Encoder (ResNet50, ImageNet) ------------------------------\n",
    "    resnet = ResNet50(weights=\"imagenet\",\n",
    "                      include_top=False,\n",
    "                      input_tensor=Input(shape=input_size))\n",
    "\n",
    "    # Feature maps for skip connections\n",
    "    skip_names = [\n",
    "        \"conv1_relu\",          # 128×128×64\n",
    "        \"conv2_block3_out\",    # 64×64×256\n",
    "        \"conv3_block4_out\",    # 32×32×512\n",
    "        \"conv4_block6_out\"     # 16×16×1024\n",
    "    ]\n",
    "    encoder_output = resnet.get_layer(\"conv5_block3_out\").output  # 8×8×2048\n",
    "\n",
    "    if freeze_encoder:\n",
    "        for layer in resnet.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "    # --- Decoder helper -------------------------------------------\n",
    "    def upsample(x, filters, name):\n",
    "        if upsample_mode == \"transpose\":\n",
    "            return Conv2DTranspose(filters, 2, strides=2, padding=\"same\",\n",
    "                                   name=f\"{name}_up\")(x)\n",
    "        # bilinear resize + conv (optional)\n",
    "        x = Lambda(lambda t: tf.image.resize(t,\n",
    "                                             (t.shape[1] * 2, t.shape[2] * 2),\n",
    "                                             method=\"bilinear\"),\n",
    "                   name=f\"{name}_resize\")(x)\n",
    "        return Conv2D(filters, 3, padding=\"same\", name=f\"{name}_conv\")(x)\n",
    "\n",
    "    # --- Decoder --------------------------------------------------\n",
    "    x = encoder_output\n",
    "    for i, (skip_name, f) in enumerate(zip(reversed(skip_names), decoder_filters), 1):\n",
    "        x = upsample(x, f, name=f\"dec{i}\")\n",
    "        skip = resnet.get_layer(skip_name).output\n",
    "        x = Concatenate(name=f\"concat{i}\")([x, skip])\n",
    "\n",
    "        x = Conv2D(f, 3, padding=\"same\", name=f\"dec{i}_conv1\")(x)\n",
    "        x = BatchNormalization(name=f\"dec{i}_bn1\")(x)\n",
    "        x = Activation(\"relu\", name=f\"dec{i}_act1\")(x)\n",
    "\n",
    "        x = Conv2D(f, 3, padding=\"same\", name=f\"dec{i}_conv2\")(x)\n",
    "        x = BatchNormalization(name=f\"dec{i}_bn2\")(x)\n",
    "        x = Activation(\"relu\", name=f\"dec{i}_act2\")(x)\n",
    "\n",
    "    # Final upsample to 256×256\n",
    "    x = upsample(x, decoder_filters[-1] // 2, name=\"dec_final\")\n",
    "\n",
    "    # Output mask\n",
    "    mask = Conv2D(1, 1, activation=final_activation,\n",
    "                  padding=\"same\", name=\"mask\")(x)\n",
    "\n",
    "    # Safeguard resize (identity for 256×256)\n",
    "    mask = Lambda(lambda t: tf.image.resize(t,\n",
    "                                            (input_size[0], input_size[1]),\n",
    "                                            method=\"bilinear\"),\n",
    "                  name=\"identity_resize\")(mask)\n",
    "\n",
    "    model = Model(inputs=resnet.input, outputs=mask, name=\"ResNet50_UNet\")\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3. Paths and hyper‑parameters\n",
    "# ------------------------------------------------------------------\n",
    "IMAGE_DIR = \"datasets2/images\"\n",
    "MASK_DIR  = \"datasets2/masks\"\n",
    "TILE_SIZE = 256\n",
    "size = 256\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 100\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4. Prepare data\n",
    "# ------------------------------------------------------------------\n",
    "X, y = load_data(IMAGE_DIR, MASK_DIR, TILE_SIZE)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# Add channel dimension to masks\n",
    "y_train = y_train[..., np.newaxis]\n",
    "y_val   = y_val[..., np.newaxis]\n",
    "y_test  = y_test[..., np.newaxis]\n",
    "\n",
    "# Data augmentation (same settings as VGG16 pipeline)\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    brightness_range=[0.8, 1.2]\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5. Callbacks\n",
    "# ------------------------------------------------------------------\n",
    "def lr_schedule(epoch):\n",
    "    base_lr = 1e-4\n",
    "    decay   = 0.9\n",
    "    return base_lr * (decay ** (epoch // 10))\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "checkpointer  = ModelCheckpoint(\"best_resnet_unet_1572025.h5\",\n",
    "                                monitor=\"val_loss\",\n",
    "                                save_best_only=True,\n",
    "                                mode=\"min\")\n",
    "\n",
    "early_stop   = EarlyStopping(monitor=\"val_loss\",\n",
    "                             patience=5,\n",
    "                             mode=\"min\",\n",
    "                             verbose=1)\n",
    "\n",
    "callbacks = [lr_scheduler, checkpointer, early_stop]\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 6. Build and train model\n",
    "# ------------------------------------------------------------------\n",
    "model = resnet50_unet(input_size=(TILE_SIZE, TILE_SIZE, 3),\n",
    "                      freeze_encoder=True)\n",
    "\n",
    "history = model.fit(datagen.flow(X_train, y_train, batch_size=BATCH_SIZE),\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    callbacks=callbacks)\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 7. Evaluate and save\n",
    "# ------------------------------------------------------------------\n",
    "loss, acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss:.4f} | Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "model.save(\"forest_detection_resnet_unet_full.h5\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 8. Plot losses\n",
    "# ------------------------------------------------------------------\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history[\"loss\"],     label=\"Train Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Val Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"resnet_unet_training_curve.png\")\n",
    "plt.close()\n",
    "print(\"Training curve saved to resnet_unet_training_curve.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d9b906a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 61s 8s/step\n",
      "Accuracy: 0.8899\n",
      "F1 Score: 0.8722\n",
      "Precision: 0.9854\n",
      "Recall: 0.7824\n",
      "Confusion Matrix:\n",
      "[[6061663   65549]\n",
      " [1233784 4435484]]\n",
      "Mean Intersection over Union (mIoU): 0.7734\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load_model('best_resnet_unet_1572025.h5')\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "# Threshold the predictions to get binary values (0 or 1)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Flatten the arrays for metrics calculation\n",
    "y_test_flat = y_test.flatten()\n",
    "y_pred_flat = y_pred_binary.flatten()\n",
    "\n",
    "# Calculate and print accuracy\n",
    "accuracy = accuracy_score(y_test_flat, y_pred_flat)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Calculate and print F1 score\n",
    "f1 = f1_score(y_test_flat, y_pred_flat)\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "# Calculate and print precision\n",
    "precision = precision_score(y_test_flat, y_pred_flat)\n",
    "print(f'Precision: {precision:.4f}')\n",
    "\n",
    "# Calculate and print recall\n",
    "recall = recall_score(y_test_flat, y_pred_flat)\n",
    "print(f'Recall: {recall:.4f}')\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test_flat, y_pred_flat)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate mean intersection over union (mIoU)\n",
    "intersection = np.sum(np.logical_and(y_test_flat, y_pred_flat))\n",
    "union = np.sum(np.logical_or(y_test_flat, y_pred_flat))\n",
    "miou = intersection / union\n",
    "print(f'Mean Intersection over Union (mIoU): {miou:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "812bffbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 63s 8s/step\n",
      "Accuracy: 0.8899\n",
      "F1 Score: 0.8722\n",
      "Precision: 0.9854\n",
      "Recall: 0.7824\n",
      "Confusion Matrix:\n",
      "[[6061663   65549]\n",
      " [1233784 4435484]]\n",
      "Mean Intersection over Union (mIoU): 0.7734\n",
      "ROC-AUC Score: 0.8917\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    "    roc_auc_score\n",
    ")\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load_model('best_resnet_unet_1572025.h5')\n",
    "\n",
    "# Predict probabilities on the test set\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "# Threshold the predictions to get binary values (0 or 1)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)\n",
    "\n",
    "# Flatten arrays for metric calculations\n",
    "y_test_flat = y_test.flatten()\n",
    "y_pred_flat = y_pred_binary.flatten()\n",
    "y_pred_prob_flat = y_pred.flatten()  # Keep raw probabilities for ROC-AUC\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test_flat, y_pred_flat)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test_flat, y_pred_flat)\n",
    "print(f'F1 Score: {f1:.4f}')\n",
    "\n",
    "# Precision\n",
    "precision = precision_score(y_test_flat, y_pred_flat)\n",
    "print(f'Precision: {precision:.4f}')\n",
    "\n",
    "# Recall\n",
    "recall = recall_score(y_test_flat, y_pred_flat)\n",
    "print(f'Recall: {recall:.4f}')\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test_flat, y_pred_flat)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "# Mean Intersection over Union (mIoU)\n",
    "intersection = np.sum(np.logical_and(y_test_flat, y_pred_flat))\n",
    "union = np.sum(np.logical_or(y_test_flat, y_pred_flat))\n",
    "miou = intersection / union\n",
    "print(f'Mean Intersection over Union (mIoU): {miou:.4f}')\n",
    "\n",
    "# ROC-AUC Score\n",
    "roc_auc = roc_auc_score(y_test_flat, y_pred_prob_flat)\n",
    "print(f'ROC-AUC Score: {roc_auc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
